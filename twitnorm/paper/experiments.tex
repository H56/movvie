\section{Experiments}
\label{sec:experiments}

subsection Data sets

We used a large amount of social media text to construct our co-occurrence graph. We extracted 15GB tweets from Stanford's 476 million Twitter Dataset\cite{DBLP:conf/wsdm/YangL11}. After tokenization we removed tokens POS tagged as mention(@brendon), discourse marker (ex: RT), URL or email addresses, emoticons, numerals, punctuations and used remaining tokens to build the graph.

After constructing the graph we only kept the nodes with a frequency greater than 8 and the edges with weight greater than 1. We had remaining 105428 nodes and 46609603 edges in the graph.

Han'ların data setini eveluation icin kullandım.

subsection Results


Section Conclusion
